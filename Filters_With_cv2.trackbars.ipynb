{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-07-25 06:32:19--  https://upload.wikimedia.org/wikipedia/en/b/b0/Black_%26_White_Handshake_-_Still_from_the_film_Colour_Blind_%282009%29.JPG\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 198.35.26.112, 2620:0:863:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|198.35.26.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 984753 (962K) [image/jpeg]\n",
      "Saving to: ‘testimage.jpg’\n",
      "\n",
      "testimage.jpg       100%[===================>] 961.67K   243KB/s    in 4.1s    \n",
      "\n",
      "2017-07-25 06:32:23 (237 KB/s) - ‘testimage.jpg’ saved [984753/984753]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O testimage.jpg https://upload.wikimedia.org/wikipedia/en/b/b0/Black_%26_White_Handshake_-_Still_from_the_film_Colour_Blind_%282009%29.JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3088\n",
      "2056\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "testimage = Image.open(\"testimage.jpg\")\n",
    "w, h = testimage.size\n",
    "print w\n",
    "print h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module PIL.Image in PIL:\n",
      "\n",
      "NAME\n",
      "    PIL.Image\n",
      "\n",
      "FILE\n",
      "    /home/jack/anaconda2/lib/python2.7/site-packages/PIL/Image.py\n",
      "\n",
      "DESCRIPTION\n",
      "    # The Python Imaging Library.\n",
      "    # $Id$\n",
      "    #\n",
      "    # the Image class wrapper\n",
      "    #\n",
      "    # partial release history:\n",
      "    # 1995-09-09 fl   Created\n",
      "    # 1996-03-11 fl   PIL release 0.0 (proof of concept)\n",
      "    # 1996-04-30 fl   PIL release 0.1b1\n",
      "    # 1999-07-28 fl   PIL release 1.0 final\n",
      "    # 2000-06-07 fl   PIL release 1.1\n",
      "    # 2000-10-20 fl   PIL release 1.1.1\n",
      "    # 2001-05-07 fl   PIL release 1.1.2\n",
      "    # 2002-03-15 fl   PIL release 1.1.3\n",
      "    # 2003-05-10 fl   PIL release 1.1.4\n",
      "    # 2005-03-28 fl   PIL release 1.1.5\n",
      "    # 2006-12-02 fl   PIL release 1.1.6\n",
      "    # 2009-11-15 fl   PIL release 1.1.7\n",
      "    #\n",
      "    # Copyright (c) 1997-2009 by Secret Labs AB.  All rights reserved.\n",
      "    # Copyright (c) 1995-2009 by Fredrik Lundh.\n",
      "    #\n",
      "    # See the README file for information on usage and redistribution.\n",
      "    #\n",
      "\n",
      "CLASSES\n",
      "    __builtin__.object\n",
      "        Image\n",
      "        ImagePointHandler\n",
      "        ImageTransformHandler\n",
      "    exceptions.RuntimeWarning(exceptions.Warning)\n",
      "        DecompressionBombWarning\n",
      "    \n",
      "    class DecompressionBombWarning(exceptions.RuntimeWarning)\n",
      "     |  Method resolution order:\n",
      "     |      DecompressionBombWarning\n",
      "     |      exceptions.RuntimeWarning\n",
      "     |      exceptions.Warning\n",
      "     |      exceptions.Exception\n",
      "     |      exceptions.BaseException\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from exceptions.RuntimeWarning:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      x.__init__(...) initializes x; see help(type(x)) for signature\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from exceptions.RuntimeWarning:\n",
      "     |  \n",
      "     |  __new__ = <built-in method __new__ of type object>\n",
      "     |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from exceptions.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(...)\n",
      "     |      x.__delattr__('name') <==> del x.name\n",
      "     |  \n",
      "     |  __getattribute__(...)\n",
      "     |      x.__getattribute__('name') <==> x.name\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      x.__getitem__(y) <==> x[y]\n",
      "     |  \n",
      "     |  __getslice__(...)\n",
      "     |      x.__getslice__(i, j) <==> x[i:j]\n",
      "     |      \n",
      "     |      Use of negative indices is not supported.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      x.__repr__() <==> repr(x)\n",
      "     |  \n",
      "     |  __setattr__(...)\n",
      "     |      x.__setattr__('name', value) <==> x.name = value\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      x.__str__() <==> str(x)\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from exceptions.BaseException:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  message\n",
      "    \n",
      "    class Image(__builtin__.object)\n",
      "     |  This class represents an image object.  To create\n",
      "     |  :py:class:`~PIL.Image.Image` objects, use the appropriate factory\n",
      "     |  functions.  There's hardly ever any reason to call the Image constructor\n",
      "     |  directly.\n",
      "     |  \n",
      "     |  * :py:func:`~PIL.Image.open`\n",
      "     |  * :py:func:`~PIL.Image.new`\n",
      "     |  * :py:func:`~PIL.Image.frombytes`\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__ = copy(self)\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      # Context Manager Support\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes the file pointer, if possible.\n",
      "     |      \n",
      "     |      This operation will destroy the image core and release its memory.\n",
      "     |      The image data will be unusable afterward.\n",
      "     |      \n",
      "     |      This function is only required to close images that have not\n",
      "     |      had their file read and closed by the\n",
      "     |      :py:meth:`~PIL.Image.Image.load` method.\n",
      "     |  \n",
      "     |  convert(self, mode=None, matrix=None, dither=None, palette=0, colors=256)\n",
      "     |      Returns a converted copy of this image. For the \"P\" mode, this\n",
      "     |      method translates pixels through the palette.  If mode is\n",
      "     |      omitted, a mode is chosen so that all information in the image\n",
      "     |      and the palette can be represented without a palette.\n",
      "     |      \n",
      "     |      The current version supports all possible conversions between\n",
      "     |      \"L\", \"RGB\" and \"CMYK.\" The **matrix** argument only supports \"L\"\n",
      "     |      and \"RGB\".\n",
      "     |      \n",
      "     |      When translating a color image to black and white (mode \"L\"),\n",
      "     |      the library uses the ITU-R 601-2 luma transform::\n",
      "     |      \n",
      "     |          L = R * 299/1000 + G * 587/1000 + B * 114/1000\n",
      "     |      \n",
      "     |      The default method of converting a greyscale (\"L\") or \"RGB\"\n",
      "     |      image into a bilevel (mode \"1\") image uses Floyd-Steinberg\n",
      "     |      dither to approximate the original image luminosity levels. If\n",
      "     |      dither is NONE, all non-zero values are set to 255 (white). To\n",
      "     |      use other thresholds, use the :py:meth:`~PIL.Image.Image.point`\n",
      "     |      method.\n",
      "     |      \n",
      "     |      :param mode: The requested mode. See: :ref:`concept-modes`.\n",
      "     |      :param matrix: An optional conversion matrix.  If given, this\n",
      "     |         should be 4- or 12-tuple containing floating point values.\n",
      "     |      :param dither: Dithering method, used when converting from\n",
      "     |         mode \"RGB\" to \"P\" or from \"RGB\" or \"L\" to \"1\".\n",
      "     |         Available methods are NONE or FLOYDSTEINBERG (default).\n",
      "     |      :param palette: Palette to use when converting from mode \"RGB\"\n",
      "     |         to \"P\".  Available palettes are WEB or ADAPTIVE.\n",
      "     |      :param colors: Number of colors to use for the ADAPTIVE palette.\n",
      "     |         Defaults to 256.\n",
      "     |      :rtype: :py:class:`~PIL.Image.Image`\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Copies this image. Use this method if you wish to paste things\n",
      "     |      into an image, but still retain the original.\n",
      "     |      \n",
      "     |      :rtype: :py:class:`~PIL.Image.Image`\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  crop(self, box=None)\n",
      "     |      Returns a rectangular region from this image. The box is a\n",
      "     |      4-tuple defining the left, upper, right, and lower pixel\n",
      "     |      coordinate.\n",
      "     |      \n",
      "     |      Note: Prior to Pillow 3.4.0, this was a lazy operation.\n",
      "     |      \n",
      "     |      :param box: The crop rectangle, as a (left, upper, right, lower)-tuple.\n",
      "     |      :rtype: :py:class:`~PIL.Image.Image`\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  draft(self, mode, size)\n",
      "     |      Configures the image file loader so it returns a version of the\n",
      "     |      image that as closely as possible matches the given mode and\n",
      "     |      size.  For example, you can use this method to convert a color\n",
      "     |      JPEG to greyscale while loading it, or to extract a 128x192\n",
      "     |      version from a PCD file.\n",
      "     |      \n",
      "     |      Note that this method modifies the :py:class:`~PIL.Image.Image` object\n",
      "     |      in place.  If the image has already been loaded, this method has no\n",
      "     |      effect.\n",
      "     |      \n",
      "     |      :param mode: The requested mode.\n",
      "     |      :param size: The requested size.\n",
      "     |  \n",
      "     |  effect_spread(self, distance)\n",
      "     |      Randomly spread pixels in an image.\n",
      "     |      \n",
      "     |      :param distance: Distance to spread pixels.\n",
      "     |  \n",
      "     |  filter(self, filter)\n",
      "     |      Filters this image using the given filter.  For a list of\n",
      "     |      available filters, see the :py:mod:`~PIL.ImageFilter` module.\n",
      "     |      \n",
      "     |      :param filter: Filter kernel.\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  frombytes(self, data, decoder_name='raw', *args)\n",
      "     |      Loads this image with pixel data from a bytes object.\n",
      "     |      \n",
      "     |      This method is similar to the :py:func:`~PIL.Image.frombytes` function,\n",
      "     |      but loads data into this image instead of creating a new image object.\n",
      "     |  \n",
      "     |  fromstring(self, *args, **kw)\n",
      "     |  \n",
      "     |  getbands(self)\n",
      "     |      Returns a tuple containing the name of each band in this image.\n",
      "     |      For example, **getbands** on an RGB image returns (\"R\", \"G\", \"B\").\n",
      "     |      \n",
      "     |      :returns: A tuple containing band names.\n",
      "     |      :rtype: tuple\n",
      "     |  \n",
      "     |  getbbox(self)\n",
      "     |      Calculates the bounding box of the non-zero regions in the\n",
      "     |      image.\n",
      "     |      \n",
      "     |      :returns: The bounding box is returned as a 4-tuple defining the\n",
      "     |         left, upper, right, and lower pixel coordinate. If the image\n",
      "     |         is completely empty, this method returns None.\n",
      "     |  \n",
      "     |  getcolors(self, maxcolors=256)\n",
      "     |      Returns a list of colors used in this image.\n",
      "     |      \n",
      "     |      :param maxcolors: Maximum number of colors.  If this number is\n",
      "     |         exceeded, this method returns None.  The default limit is\n",
      "     |         256 colors.\n",
      "     |      :returns: An unsorted list of (count, pixel) values.\n",
      "     |  \n",
      "     |  getdata(self, band=None)\n",
      "     |      Returns the contents of this image as a sequence object\n",
      "     |      containing pixel values.  The sequence object is flattened, so\n",
      "     |      that values for line one follow directly after the values of\n",
      "     |      line zero, and so on.\n",
      "     |      \n",
      "     |      Note that the sequence object returned by this method is an\n",
      "     |      internal PIL data type, which only supports certain sequence\n",
      "     |      operations.  To convert it to an ordinary sequence (e.g. for\n",
      "     |      printing), use **list(im.getdata())**.\n",
      "     |      \n",
      "     |      :param band: What band to return.  The default is to return\n",
      "     |         all bands.  To return a single band, pass in the index\n",
      "     |         value (e.g. 0 to get the \"R\" band from an \"RGB\" image).\n",
      "     |      :returns: A sequence-like object.\n",
      "     |  \n",
      "     |  getextrema(self)\n",
      "     |      Gets the the minimum and maximum pixel values for each band in\n",
      "     |      the image.\n",
      "     |      \n",
      "     |      :returns: For a single-band image, a 2-tuple containing the\n",
      "     |         minimum and maximum pixel value.  For a multi-band image,\n",
      "     |         a tuple containing one 2-tuple for each band.\n",
      "     |  \n",
      "     |  getim(self)\n",
      "     |      Returns a capsule that points to the internal image memory.\n",
      "     |      \n",
      "     |      :returns: A capsule object.\n",
      "     |  \n",
      "     |  getpalette(self)\n",
      "     |      Returns the image palette as a list.\n",
      "     |      \n",
      "     |      :returns: A list of color values [r, g, b, ...], or None if the\n",
      "     |         image has no palette.\n",
      "     |  \n",
      "     |  getpixel(self, xy)\n",
      "     |      Returns the pixel value at a given position.\n",
      "     |      \n",
      "     |      :param xy: The coordinate, given as (x, y).\n",
      "     |      :returns: The pixel value.  If the image is a multi-layer image,\n",
      "     |         this method returns a tuple.\n",
      "     |  \n",
      "     |  getprojection(self)\n",
      "     |      Get projection to x and y axes\n",
      "     |      \n",
      "     |      :returns: Two sequences, indicating where there are non-zero\n",
      "     |          pixels along the X-axis and the Y-axis, respectively.\n",
      "     |  \n",
      "     |  histogram(self, mask=None, extrema=None)\n",
      "     |      Returns a histogram for the image. The histogram is returned as\n",
      "     |      a list of pixel counts, one for each pixel value in the source\n",
      "     |      image. If the image has more than one band, the histograms for\n",
      "     |      all bands are concatenated (for example, the histogram for an\n",
      "     |      \"RGB\" image contains 768 values).\n",
      "     |      \n",
      "     |      A bilevel image (mode \"1\") is treated as a greyscale (\"L\") image\n",
      "     |      by this method.\n",
      "     |      \n",
      "     |      If a mask is provided, the method returns a histogram for those\n",
      "     |      parts of the image where the mask image is non-zero. The mask\n",
      "     |      image must have the same size as the image, and be either a\n",
      "     |      bi-level image (mode \"1\") or a greyscale image (\"L\").\n",
      "     |      \n",
      "     |      :param mask: An optional mask.\n",
      "     |      :returns: A list containing pixel counts.\n",
      "     |  \n",
      "     |  load(self)\n",
      "     |      Allocates storage for the image and loads the pixel data.  In\n",
      "     |      normal cases, you don't need to call this method, since the\n",
      "     |      Image class automatically loads an opened image when it is\n",
      "     |      accessed for the first time. This method will close the file\n",
      "     |      associated with the image.\n",
      "     |      \n",
      "     |      :returns: An image access object.\n",
      "     |      :rtype: :ref:`PixelAccess` or :py:class:`PIL.PyAccess`\n",
      "     |  \n",
      "     |  offset(self, xoffset, yoffset=None)\n",
      "     |  \n",
      "     |  paste(self, im, box=None, mask=None)\n",
      "     |      Pastes another image into this image. The box argument is either\n",
      "     |      a 2-tuple giving the upper left corner, a 4-tuple defining the\n",
      "     |      left, upper, right, and lower pixel coordinate, or None (same as\n",
      "     |      (0, 0)).  If a 4-tuple is given, the size of the pasted image\n",
      "     |      must match the size of the region.\n",
      "     |      \n",
      "     |      If the modes don't match, the pasted image is converted to the mode of\n",
      "     |      this image (see the :py:meth:`~PIL.Image.Image.convert` method for\n",
      "     |      details).\n",
      "     |      \n",
      "     |      Instead of an image, the source can be a integer or tuple\n",
      "     |      containing pixel values.  The method then fills the region\n",
      "     |      with the given color.  When creating RGB images, you can\n",
      "     |      also use color strings as supported by the ImageColor module.\n",
      "     |      \n",
      "     |      If a mask is given, this method updates only the regions\n",
      "     |      indicated by the mask.  You can use either \"1\", \"L\" or \"RGBA\"\n",
      "     |      images (in the latter case, the alpha band is used as mask).\n",
      "     |      Where the mask is 255, the given image is copied as is.  Where\n",
      "     |      the mask is 0, the current value is preserved.  Intermediate\n",
      "     |      values will mix the two images together, including their alpha\n",
      "     |      channels if they have them.\n",
      "     |      \n",
      "     |      See :py:meth:`~PIL.Image.Image.alpha_composite` if you want to\n",
      "     |      combine images with respect to their alpha channels.\n",
      "     |      \n",
      "     |      :param im: Source image or pixel value (integer or tuple).\n",
      "     |      :param box: An optional 4-tuple giving the region to paste into.\n",
      "     |         If a 2-tuple is used instead, it's treated as the upper left\n",
      "     |         corner.  If omitted or None, the source is pasted into the\n",
      "     |         upper left corner.\n",
      "     |      \n",
      "     |         If an image is given as the second argument and there is no\n",
      "     |         third, the box defaults to (0, 0), and the second argument\n",
      "     |         is interpreted as a mask image.\n",
      "     |      :param mask: An optional mask image.\n",
      "     |  \n",
      "     |  point(self, lut, mode=None)\n",
      "     |      Maps this image through a lookup table or function.\n",
      "     |      \n",
      "     |      :param lut: A lookup table, containing 256 (or 65336 if\n",
      "     |         self.mode==\"I\" and mode == \"L\") values per band in the\n",
      "     |         image.  A function can be used instead, it should take a\n",
      "     |         single argument. The function is called once for each\n",
      "     |         possible pixel value, and the resulting table is applied to\n",
      "     |         all bands of the image.\n",
      "     |      :param mode: Output mode (default is same as input).  In the\n",
      "     |         current version, this can only be used if the source image\n",
      "     |         has mode \"L\" or \"P\", and the output has mode \"1\" or the\n",
      "     |         source image mode is \"I\" and the output mode is \"L\".\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  putalpha(self, alpha)\n",
      "     |      Adds or replaces the alpha layer in this image.  If the image\n",
      "     |      does not have an alpha layer, it's converted to \"LA\" or \"RGBA\".\n",
      "     |      The new layer must be either \"L\" or \"1\".\n",
      "     |      \n",
      "     |      :param alpha: The new alpha layer.  This can either be an \"L\" or \"1\"\n",
      "     |         image having the same size as this image, or an integer or\n",
      "     |         other color value.\n",
      "     |  \n",
      "     |  putdata(self, data, scale=1.0, offset=0.0)\n",
      "     |      Copies pixel data to this image.  This method copies data from a\n",
      "     |      sequence object into the image, starting at the upper left\n",
      "     |      corner (0, 0), and continuing until either the image or the\n",
      "     |      sequence ends.  The scale and offset values are used to adjust\n",
      "     |      the sequence values: **pixel = value*scale + offset**.\n",
      "     |      \n",
      "     |      :param data: A sequence object.\n",
      "     |      :param scale: An optional scale value.  The default is 1.0.\n",
      "     |      :param offset: An optional offset value.  The default is 0.0.\n",
      "     |  \n",
      "     |  putpalette(self, data, rawmode='RGB')\n",
      "     |      Attaches a palette to this image.  The image must be a \"P\" or\n",
      "     |      \"L\" image, and the palette sequence must contain 768 integer\n",
      "     |      values, where each group of three values represent the red,\n",
      "     |      green, and blue values for the corresponding pixel\n",
      "     |      index. Instead of an integer sequence, you can use an 8-bit\n",
      "     |      string.\n",
      "     |      \n",
      "     |      :param data: A palette sequence (either a list or a string).\n",
      "     |  \n",
      "     |  putpixel(self, xy, value)\n",
      "     |      Modifies the pixel at the given position. The color is given as\n",
      "     |      a single numerical value for single-band images, and a tuple for\n",
      "     |      multi-band images.\n",
      "     |      \n",
      "     |      Note that this method is relatively slow.  For more extensive changes,\n",
      "     |      use :py:meth:`~PIL.Image.Image.paste` or the :py:mod:`~PIL.ImageDraw`\n",
      "     |      module instead.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      \n",
      "     |      * :py:meth:`~PIL.Image.Image.paste`\n",
      "     |      * :py:meth:`~PIL.Image.Image.putdata`\n",
      "     |      * :py:mod:`~PIL.ImageDraw`\n",
      "     |      \n",
      "     |      :param xy: The pixel coordinate, given as (x, y).\n",
      "     |      :param value: The pixel value.\n",
      "     |  \n",
      "     |  quantize(self, colors=256, method=None, kmeans=0, palette=None)\n",
      "     |      Convert the image to 'P' mode with the specified number\n",
      "     |      of colors.\n",
      "     |      \n",
      "     |      :param colors: The desired number of colors, <= 256\n",
      "     |      :param method: 0 = median cut\n",
      "     |                     1 = maximum coverage\n",
      "     |                     2 = fast octree\n",
      "     |                     3 = libimagequant\n",
      "     |      :param kmeans: Integer\n",
      "     |      :param palette: Quantize to the :py:class:`PIL.ImagingPalette` palette.\n",
      "     |      :returns: A new image\n",
      "     |  \n",
      "     |  remap_palette(self, dest_map, source_palette=None)\n",
      "     |      Rewrites the image to reorder the palette.\n",
      "     |      \n",
      "     |      :param dest_map: A list of indexes into the original palette.\n",
      "     |         e.g. [1,0] would swap a two item palette, and list(range(255))\n",
      "     |         is the identity transform.\n",
      "     |      :param source_palette: Bytes or None.\n",
      "     |      :returns:  An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  resize(self, size, resample=0)\n",
      "     |      Returns a resized copy of this image.\n",
      "     |      \n",
      "     |      :param size: The requested size in pixels, as a 2-tuple:\n",
      "     |         (width, height).\n",
      "     |      :param resample: An optional resampling filter.  This can be\n",
      "     |         one of :py:attr:`PIL.Image.NEAREST`, :py:attr:`PIL.Image.BOX`,\n",
      "     |         :py:attr:`PIL.Image.BILINEAR`, :py:attr:`PIL.Image.HAMMING`,\n",
      "     |         :py:attr:`PIL.Image.BICUBIC` or :py:attr:`PIL.Image.LANCZOS`.\n",
      "     |         If omitted, or if the image has mode \"1\" or \"P\", it is\n",
      "     |         set :py:attr:`PIL.Image.NEAREST`.\n",
      "     |         See: :ref:`concept-filters`.\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  rotate(self, angle, resample=0, expand=0, center=None, translate=None)\n",
      "     |      Returns a rotated copy of this image.  This method returns a\n",
      "     |      copy of this image, rotated the given number of degrees counter\n",
      "     |      clockwise around its centre.\n",
      "     |      \n",
      "     |      :param angle: In degrees counter clockwise.\n",
      "     |      :param resample: An optional resampling filter.  This can be\n",
      "     |         one of :py:attr:`PIL.Image.NEAREST` (use nearest neighbour),\n",
      "     |         :py:attr:`PIL.Image.BILINEAR` (linear interpolation in a 2x2\n",
      "     |         environment), or :py:attr:`PIL.Image.BICUBIC`\n",
      "     |         (cubic spline interpolation in a 4x4 environment).\n",
      "     |         If omitted, or if the image has mode \"1\" or \"P\", it is\n",
      "     |         set :py:attr:`PIL.Image.NEAREST`. See :ref:`concept-filters`.\n",
      "     |      :param expand: Optional expansion flag.  If true, expands the output\n",
      "     |         image to make it large enough to hold the entire rotated image.\n",
      "     |         If false or omitted, make the output image the same size as the\n",
      "     |         input image.  Note that the expand flag assumes rotation around\n",
      "     |         the center and no translation.\n",
      "     |      :param center: Optional center of rotation (a 2-tuple).  Origin is\n",
      "     |         the upper left corner.  Default is the center of the image.\n",
      "     |      :param translate: An optional post-rotate translation (a 2-tuple).\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  save(self, fp, format=None, **params)\n",
      "     |      Saves this image under the given filename.  If no format is\n",
      "     |      specified, the format to use is determined from the filename\n",
      "     |      extension, if possible.\n",
      "     |      \n",
      "     |      Keyword options can be used to provide additional instructions\n",
      "     |      to the writer. If a writer doesn't recognise an option, it is\n",
      "     |      silently ignored. The available options are described in the\n",
      "     |      :doc:`image format documentation\n",
      "     |      <../handbook/image-file-formats>` for each writer.\n",
      "     |      \n",
      "     |      You can use a file object instead of a filename. In this case,\n",
      "     |      you must always specify the format. The file object must\n",
      "     |      implement the ``seek``, ``tell``, and ``write``\n",
      "     |      methods, and be opened in binary mode.\n",
      "     |      \n",
      "     |      :param fp: A filename (string), pathlib.Path object or file object.\n",
      "     |      :param format: Optional format override.  If omitted, the\n",
      "     |         format to use is determined from the filename extension.\n",
      "     |         If a file object was used instead of a filename, this\n",
      "     |         parameter should always be used.\n",
      "     |      :param options: Extra parameters to the image writer.\n",
      "     |      :returns: None\n",
      "     |      :exception KeyError: If the output format could not be determined\n",
      "     |         from the file name.  Use the format option to solve this.\n",
      "     |      :exception IOError: If the file could not be written.  The file\n",
      "     |         may have been created, and may contain partial data.\n",
      "     |  \n",
      "     |  seek(self, frame)\n",
      "     |      Seeks to the given frame in this sequence file. If you seek\n",
      "     |      beyond the end of the sequence, the method raises an\n",
      "     |      **EOFError** exception. When a sequence file is opened, the\n",
      "     |      library automatically seeks to frame 0.\n",
      "     |      \n",
      "     |      Note that in the current version of the library, most sequence\n",
      "     |      formats only allows you to seek to the next frame.\n",
      "     |      \n",
      "     |      See :py:meth:`~PIL.Image.Image.tell`.\n",
      "     |      \n",
      "     |      :param frame: Frame number, starting at 0.\n",
      "     |      :exception EOFError: If the call attempts to seek beyond the end\n",
      "     |          of the sequence.\n",
      "     |  \n",
      "     |  show(self, title=None, command=None)\n",
      "     |      Displays this image. This method is mainly intended for\n",
      "     |      debugging purposes.\n",
      "     |      \n",
      "     |      On Unix platforms, this method saves the image to a temporary\n",
      "     |      PPM file, and calls either the **xv** utility or the **display**\n",
      "     |      utility, depending on which one can be found.\n",
      "     |      \n",
      "     |      On macOS, this method saves the image to a temporary BMP file, and\n",
      "     |      opens it with the native Preview application.\n",
      "     |      \n",
      "     |      On Windows, it saves the image to a temporary BMP file, and uses\n",
      "     |      the standard BMP display utility to show it (usually Paint).\n",
      "     |      \n",
      "     |      :param title: Optional title to use for the image window,\n",
      "     |         where possible.\n",
      "     |      :param command: command used to show the image\n",
      "     |  \n",
      "     |  split(self)\n",
      "     |      Split this image into individual bands. This method returns a\n",
      "     |      tuple of individual image bands from an image. For example,\n",
      "     |      splitting an \"RGB\" image creates three new images each\n",
      "     |      containing a copy of one of the original bands (red, green,\n",
      "     |      blue).\n",
      "     |      \n",
      "     |      :returns: A tuple containing bands.\n",
      "     |  \n",
      "     |  tell(self)\n",
      "     |      Returns the current frame number. See :py:meth:`~PIL.Image.Image.seek`.\n",
      "     |      \n",
      "     |      :returns: Frame number, starting with 0.\n",
      "     |  \n",
      "     |  thumbnail(self, size, resample=3)\n",
      "     |      Make this image into a thumbnail.  This method modifies the\n",
      "     |      image to contain a thumbnail version of itself, no larger than\n",
      "     |      the given size.  This method calculates an appropriate thumbnail\n",
      "     |      size to preserve the aspect of the image, calls the\n",
      "     |      :py:meth:`~PIL.Image.Image.draft` method to configure the file reader\n",
      "     |      (where applicable), and finally resizes the image.\n",
      "     |      \n",
      "     |      Note that this function modifies the :py:class:`~PIL.Image.Image`\n",
      "     |      object in place.  If you need to use the full resolution image as well,\n",
      "     |      apply this method to a :py:meth:`~PIL.Image.Image.copy` of the original\n",
      "     |      image.\n",
      "     |      \n",
      "     |      :param size: Requested size.\n",
      "     |      :param resample: Optional resampling filter.  This can be one\n",
      "     |         of :py:attr:`PIL.Image.NEAREST`, :py:attr:`PIL.Image.BILINEAR`,\n",
      "     |         :py:attr:`PIL.Image.BICUBIC`, or :py:attr:`PIL.Image.LANCZOS`.\n",
      "     |         If omitted, it defaults to :py:attr:`PIL.Image.BICUBIC`.\n",
      "     |         (was :py:attr:`PIL.Image.NEAREST` prior to version 2.5.0)\n",
      "     |      :returns: None\n",
      "     |  \n",
      "     |  tobitmap(self, name='image')\n",
      "     |      Returns the image converted to an X11 bitmap.\n",
      "     |      \n",
      "     |      .. note:: This method only works for mode \"1\" images.\n",
      "     |      \n",
      "     |      :param name: The name prefix to use for the bitmap variables.\n",
      "     |      :returns: A string containing an X11 bitmap.\n",
      "     |      :raises ValueError: If the mode is not \"1\"\n",
      "     |  \n",
      "     |  tobytes(self, encoder_name='raw', *args)\n",
      "     |      Return image as a bytes object.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This method returns the raw image data from the internal\n",
      "     |          storage.  For compressed image data (e.g. PNG, JPEG) use\n",
      "     |          :meth:`~.save`, with a BytesIO parameter for in-memory\n",
      "     |          data.\n",
      "     |      \n",
      "     |      :param encoder_name: What encoder to use.  The default is to\n",
      "     |                           use the standard \"raw\" encoder.\n",
      "     |      :param args: Extra arguments to the encoder.\n",
      "     |      :rtype: A bytes object.\n",
      "     |  \n",
      "     |  toqimage(self)\n",
      "     |      Returns a QImage copy of this image\n",
      "     |  \n",
      "     |  toqpixmap(self)\n",
      "     |      Returns a QPixmap copy of this image\n",
      "     |  \n",
      "     |  tostring(self, *args, **kw)\n",
      "     |  \n",
      "     |  transform(self, size, method, data=None, resample=0, fill=1)\n",
      "     |      Transforms this image.  This method creates a new image with the\n",
      "     |      given size, and the same mode as the original, and copies data\n",
      "     |      to the new image using the given transform.\n",
      "     |      \n",
      "     |      :param size: The output size.\n",
      "     |      :param method: The transformation method.  This is one of\n",
      "     |        :py:attr:`PIL.Image.EXTENT` (cut out a rectangular subregion),\n",
      "     |        :py:attr:`PIL.Image.AFFINE` (affine transform),\n",
      "     |        :py:attr:`PIL.Image.PERSPECTIVE` (perspective transform),\n",
      "     |        :py:attr:`PIL.Image.QUAD` (map a quadrilateral to a rectangle), or\n",
      "     |        :py:attr:`PIL.Image.MESH` (map a number of source quadrilaterals\n",
      "     |        in one operation).\n",
      "     |      :param data: Extra data to the transformation method.\n",
      "     |      :param resample: Optional resampling filter.  It can be one of\n",
      "     |         :py:attr:`PIL.Image.NEAREST` (use nearest neighbour),\n",
      "     |         :py:attr:`PIL.Image.BILINEAR` (linear interpolation in a 2x2\n",
      "     |         environment), or :py:attr:`PIL.Image.BICUBIC` (cubic spline\n",
      "     |         interpolation in a 4x4 environment). If omitted, or if the image\n",
      "     |         has mode \"1\" or \"P\", it is set to :py:attr:`PIL.Image.NEAREST`.\n",
      "     |      :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "     |  \n",
      "     |  transpose(self, method)\n",
      "     |      Transpose image (flip or rotate in 90 degree steps)\n",
      "     |      \n",
      "     |      :param method: One of :py:attr:`PIL.Image.FLIP_LEFT_RIGHT`,\n",
      "     |        :py:attr:`PIL.Image.FLIP_TOP_BOTTOM`, :py:attr:`PIL.Image.ROTATE_90`,\n",
      "     |        :py:attr:`PIL.Image.ROTATE_180`, :py:attr:`PIL.Image.ROTATE_270` or\n",
      "     |        :py:attr:`PIL.Image.TRANSPOSE`.\n",
      "     |      :returns: Returns a flipped or rotated copy of this image.\n",
      "     |  \n",
      "     |  verify(self)\n",
      "     |      Verifies the contents of a file. For data read from a file, this\n",
      "     |      method attempts to determine if the file is broken, without\n",
      "     |      actually decoding the image data.  If this method finds any\n",
      "     |      problems, it raises suitable exceptions.  If you need to load\n",
      "     |      the image after using this method, you must reopen the image\n",
      "     |      file.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __array_interface__\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  height\n",
      "     |  \n",
      "     |  width\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  format = None\n",
      "     |  \n",
      "     |  format_description = None\n",
      "    \n",
      "    class ImagePointHandler(__builtin__.object)\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ImageTransformHandler(__builtin__.object)\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    alpha_composite(im1, im2)\n",
      "        Alpha composite im2 over im1.\n",
      "        \n",
      "        :param im1: The first image. Must have mode RGBA.\n",
      "        :param im2: The second image.  Must have mode RGBA, and the same size as\n",
      "           the first image.\n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "    \n",
      "    blend(im1, im2, alpha)\n",
      "        Creates a new image by interpolating between two input images, using\n",
      "        a constant alpha.::\n",
      "        \n",
      "            out = image1 * (1.0 - alpha) + image2 * alpha\n",
      "        \n",
      "        :param im1: The first image.\n",
      "        :param im2: The second image.  Must have the same mode and size as\n",
      "           the first image.\n",
      "        :param alpha: The interpolation alpha factor.  If alpha is 0.0, a\n",
      "           copy of the first image is returned. If alpha is 1.0, a copy of\n",
      "           the second image is returned. There are no restrictions on the\n",
      "           alpha value. If necessary, the result is clipped to fit into\n",
      "           the allowed output range.\n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "    \n",
      "    coerce_e(value)\n",
      "    \n",
      "    composite(image1, image2, mask)\n",
      "        Create composite image by blending images using a transparency mask.\n",
      "        \n",
      "        :param image1: The first image.\n",
      "        :param image2: The second image.  Must have the same mode and\n",
      "           size as the first image.\n",
      "        :param mask: A mask image.  This image can have mode\n",
      "           \"1\", \"L\", or \"RGBA\", and must have the same size as the\n",
      "           other two images.\n",
      "    \n",
      "    effect_mandelbrot(size, extent, quality)\n",
      "        Generate a Mandelbrot set covering the given extent.\n",
      "        \n",
      "        :param size: The requested size in pixels, as a 2-tuple:\n",
      "           (width, height).\n",
      "        :param extent: The extent to cover, as a 4-tuple:\n",
      "           (x0, y0, x1, y2).\n",
      "        :param quality: Quality.\n",
      "    \n",
      "    effect_noise(size, sigma)\n",
      "        Generate Gaussian noise centered around 128.\n",
      "        \n",
      "        :param size: The requested size in pixels, as a 2-tuple:\n",
      "           (width, height).\n",
      "        :param sigma: Standard deviation of noise.\n",
      "    \n",
      "    eval(image, *args)\n",
      "        Applies the function (which should take one argument) to each pixel\n",
      "        in the given image. If the image has more than one band, the same\n",
      "        function is applied to each band. Note that the function is\n",
      "        evaluated once for each possible pixel value, so you cannot use\n",
      "        random components or other generators.\n",
      "        \n",
      "        :param image: The input image.\n",
      "        :param function: A function object, taking one integer argument.\n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "    \n",
      "    fromarray(obj, mode=None)\n",
      "        Creates an image memory from an object exporting the array interface\n",
      "        (using the buffer protocol).\n",
      "        \n",
      "        If obj is not contiguous, then the tobytes method is called\n",
      "        and :py:func:`~PIL.Image.frombuffer` is used.\n",
      "        \n",
      "        :param obj: Object with array interface\n",
      "        :param mode: Mode to use (will be determined from type if None)\n",
      "          See: :ref:`concept-modes`.\n",
      "        :returns: An image object.\n",
      "        \n",
      "        .. versionadded:: 1.1.6\n",
      "    \n",
      "    frombuffer(mode, size, data, decoder_name='raw', *args)\n",
      "        Creates an image memory referencing pixel data in a byte buffer.\n",
      "        \n",
      "        This function is similar to :py:func:`~PIL.Image.frombytes`, but uses data\n",
      "        in the byte buffer, where possible.  This means that changes to the\n",
      "        original buffer object are reflected in this image).  Not all modes can\n",
      "        share memory; supported modes include \"L\", \"RGBX\", \"RGBA\", and \"CMYK\".\n",
      "        \n",
      "        Note that this function decodes pixel data only, not entire images.\n",
      "        If you have an entire image file in a string, wrap it in a\n",
      "        **BytesIO** object, and use :py:func:`~PIL.Image.open` to load it.\n",
      "        \n",
      "        In the current version, the default parameters used for the \"raw\" decoder\n",
      "        differs from that used for :py:func:`~PIL.Image.frombytes`.  This is a\n",
      "        bug, and will probably be fixed in a future release.  The current release\n",
      "        issues a warning if you do this; to disable the warning, you should provide\n",
      "        the full set of parameters.  See below for details.\n",
      "        \n",
      "        :param mode: The image mode. See: :ref:`concept-modes`.\n",
      "        :param size: The image size.\n",
      "        :param data: A bytes or other buffer object containing raw\n",
      "            data for the given mode.\n",
      "        :param decoder_name: What decoder to use.\n",
      "        :param args: Additional parameters for the given decoder.  For the\n",
      "            default encoder (\"raw\"), it's recommended that you provide the\n",
      "            full set of parameters::\n",
      "        \n",
      "                frombuffer(mode, size, data, \"raw\", mode, 0, 1)\n",
      "        \n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "        \n",
      "        .. versionadded:: 1.1.4\n",
      "    \n",
      "    frombytes(mode, size, data, decoder_name='raw', *args)\n",
      "        Creates a copy of an image memory from pixel data in a buffer.\n",
      "        \n",
      "        In its simplest form, this function takes three arguments\n",
      "        (mode, size, and unpacked pixel data).\n",
      "        \n",
      "        You can also use any pixel decoder supported by PIL.  For more\n",
      "        information on available decoders, see the section\n",
      "        :ref:`Writing Your Own File Decoder <file-decoders>`.\n",
      "        \n",
      "        Note that this function decodes pixel data only, not entire images.\n",
      "        If you have an entire image in a string, wrap it in a\n",
      "        :py:class:`~io.BytesIO` object, and use :py:func:`~PIL.Image.open` to load\n",
      "        it.\n",
      "        \n",
      "        :param mode: The image mode. See: :ref:`concept-modes`.\n",
      "        :param size: The image size.\n",
      "        :param data: A byte buffer containing raw data for the given mode.\n",
      "        :param decoder_name: What decoder to use.\n",
      "        :param args: Additional parameters for the given decoder.\n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "    \n",
      "    fromqimage(im)\n",
      "        Creates an image instance from a QImage image\n",
      "    \n",
      "    fromqpixmap(im)\n",
      "        Creates an image instance from a QPixmap image\n",
      "    \n",
      "    fromstring(*args, **kw)\n",
      "    \n",
      "    getmodebandnames(mode)\n",
      "        Gets a list of individual band names.  Given a mode, this function returns\n",
      "        a tuple containing the names of individual bands (use\n",
      "        :py:method:`~PIL.Image.getmodetype` to get the mode used to store each\n",
      "        individual band.\n",
      "        \n",
      "        :param mode: Input mode.\n",
      "        :returns: A tuple containing band names.  The length of the tuple\n",
      "            gives the number of bands in an image of the given mode.\n",
      "        :exception KeyError: If the input mode was not a standard mode.\n",
      "    \n",
      "    getmodebands(mode)\n",
      "        Gets the number of individual bands for this mode.\n",
      "        \n",
      "        :param mode: Input mode.\n",
      "        :returns: The number of bands in this mode.\n",
      "        :exception KeyError: If the input mode was not a standard mode.\n",
      "    \n",
      "    getmodebase(mode)\n",
      "        Gets the \"base\" mode for given mode.  This function returns \"L\" for\n",
      "        images that contain grayscale data, and \"RGB\" for images that\n",
      "        contain color data.\n",
      "        \n",
      "        :param mode: Input mode.\n",
      "        :returns: \"L\" or \"RGB\".\n",
      "        :exception KeyError: If the input mode was not a standard mode.\n",
      "    \n",
      "    getmodetype(mode)\n",
      "        Gets the storage type mode.  Given a mode, this function returns a\n",
      "        single-layer mode suitable for storing individual bands.\n",
      "        \n",
      "        :param mode: Input mode.\n",
      "        :returns: \"L\", \"I\", or \"F\".\n",
      "        :exception KeyError: If the input mode was not a standard mode.\n",
      "    \n",
      "    init()\n",
      "        Explicitly initializes the Python Imaging Library. This function\n",
      "        loads all available file format drivers.\n",
      "    \n",
      "    isImageType(t)\n",
      "        Checks if an object is an image object.\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "           This function is for internal use only.\n",
      "        \n",
      "        :param t: object to check if it's an image\n",
      "        :returns: True if the object is an image\n",
      "    \n",
      "    linear_gradient(mode)\n",
      "        Generate 256x256 linear gradient from black to white, top to bottom.\n",
      "        \n",
      "        :param mode: Input mode.\n",
      "    \n",
      "    merge(mode, bands)\n",
      "        Merge a set of single band images into a new multiband image.\n",
      "        \n",
      "        :param mode: The mode to use for the output image. See:\n",
      "            :ref:`concept-modes`.\n",
      "        :param bands: A sequence containing one single-band image for\n",
      "            each band in the output image.  All bands must have the\n",
      "            same size.\n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "    \n",
      "    new(mode, size, color=0)\n",
      "        Creates a new image with the given mode and size.\n",
      "        \n",
      "        :param mode: The mode to use for the new image. See:\n",
      "           :ref:`concept-modes`.\n",
      "        :param size: A 2-tuple, containing (width, height) in pixels.\n",
      "        :param color: What color to use for the image.  Default is black.\n",
      "           If given, this should be a single integer or floating point value\n",
      "           for single-band modes, and a tuple for multi-band modes (one value\n",
      "           per band).  When creating RGB images, you can also use color\n",
      "           strings as supported by the ImageColor module.  If the color is\n",
      "           None, the image is not initialised.\n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "    \n",
      "    open(fp, mode='r')\n",
      "        Opens and identifies the given image file.\n",
      "        \n",
      "        This is a lazy operation; this function identifies the file, but\n",
      "        the file remains open and the actual image data is not read from\n",
      "        the file until you try to process the data (or call the\n",
      "        :py:meth:`~PIL.Image.Image.load` method).  See\n",
      "        :py:func:`~PIL.Image.new`.\n",
      "        \n",
      "        :param fp: A filename (string), pathlib.Path object or a file object.\n",
      "           The file object must implement :py:meth:`~file.read`,\n",
      "           :py:meth:`~file.seek`, and :py:meth:`~file.tell` methods,\n",
      "           and be opened in binary mode.\n",
      "        :param mode: The mode.  If given, this argument must be \"r\".\n",
      "        :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "        :exception IOError: If the file cannot be found, or the image cannot be\n",
      "           opened and identified.\n",
      "    \n",
      "    preinit()\n",
      "        Explicitly load standard file format drivers.\n",
      "    \n",
      "    radial_gradient(mode)\n",
      "        Generate 256x256 radial gradient from black to white, centre to edge.\n",
      "        \n",
      "        :param mode: Input mode.\n",
      "    \n",
      "    register_decoder(name, decoder)\n",
      "        Registers an image decoder.  This function should not be\n",
      "        used in application code.\n",
      "        \n",
      "        :param name: The name of the decoder\n",
      "        :param decoder: A callable(mode, args) that returns an\n",
      "                        ImageFile.PyDecoder object\n",
      "        \n",
      "        .. versionadded:: 4.1.0\n",
      "    \n",
      "    register_encoder(name, encoder)\n",
      "        Registers an image encoder.  This function should not be\n",
      "        used in application code.\n",
      "        \n",
      "        :param name: The name of the encoder\n",
      "        :param encoder: A callable(mode, args) that returns an\n",
      "                        ImageFile.PyEncoder object\n",
      "        \n",
      "        .. versionadded:: 4.1.0\n",
      "    \n",
      "    register_extension(id, extension)\n",
      "        Registers an image extension.  This function should not be\n",
      "        used in application code.\n",
      "        \n",
      "        :param id: An image format identifier.\n",
      "        :param extension: An extension used for this format.\n",
      "    \n",
      "    register_mime(id, mimetype)\n",
      "        Registers an image MIME type.  This function should not be used\n",
      "        in application code.\n",
      "        \n",
      "        :param id: An image format identifier.\n",
      "        :param mimetype: The image MIME type for this format.\n",
      "    \n",
      "    register_open(id, factory, accept=None)\n",
      "        Register an image file plugin.  This function should not be used\n",
      "        in application code.\n",
      "        \n",
      "        :param id: An image format identifier.\n",
      "        :param factory: An image file factory method.\n",
      "        :param accept: An optional function that can be used to quickly\n",
      "           reject images having another format.\n",
      "    \n",
      "    register_save(id, driver)\n",
      "        Registers an image save function.  This function should not be\n",
      "        used in application code.\n",
      "        \n",
      "        :param id: An image format identifier.\n",
      "        :param driver: A function to save images in this format.\n",
      "    \n",
      "    register_save_all(id, driver)\n",
      "        Registers an image function to save all the frames\n",
      "        of a multiframe format.  This function should not be\n",
      "        used in application code.\n",
      "        \n",
      "        :param id: An image format identifier.\n",
      "        :param driver: A function to save images in this format.\n",
      "    \n",
      "    registered_extensions()\n",
      "        Returns a dictionary containing all file extensions belonging\n",
      "        to registered plugins\n",
      "\n",
      "DATA\n",
      "    ADAPTIVE = 1\n",
      "    AFFINE = 0\n",
      "    ANTIALIAS = 1\n",
      "    BICUBIC = 3\n",
      "    BILINEAR = 2\n",
      "    BOX = 4\n",
      "    CONTAINER = 2\n",
      "    CUBIC = 3\n",
      "    DECODERS = {}\n",
      "    DEFAULT_STRATEGY = 0\n",
      "    ENCODERS = {}\n",
      "    EXTENSION = {'.bmp': 'BMP', '.gif': 'GIF', '.jfif': 'JPEG', '.jpe': 'J...\n",
      "    EXTENT = 1\n",
      "    FASTOCTREE = 2\n",
      "    FILTERED = 1\n",
      "    FIXED = 4\n",
      "    FLIP_LEFT_RIGHT = 0\n",
      "    FLIP_TOP_BOTTOM = 1\n",
      "    FLOYDSTEINBERG = 3\n",
      "    HAMMING = 5\n",
      "    HAS_CFFI = True\n",
      "    HUFFMAN_ONLY = 2\n",
      "    ID = ['BMP', 'GIF', 'TIFF', 'JPEG', 'PPM', 'PNG']\n",
      "    LANCZOS = 1\n",
      "    LIBIMAGEQUANT = 3\n",
      "    LINEAR = 2\n",
      "    MAXCOVERAGE = 1\n",
      "    MAX_IMAGE_PIXELS = 89478485\n",
      "    MEDIANCUT = 0\n",
      "    MESH = 4\n",
      "    MIME = {'BMP': 'image/bmp', 'GIF': 'image/gif', 'JPEG': 'image/jpeg', ...\n",
      "    MODES = ['1', 'CMYK', 'F', 'HSV', 'I', 'L', 'LAB', 'P', 'RGB', 'RGBA',...\n",
      "    NEAREST = 0\n",
      "    NONE = 0\n",
      "    NORMAL = 0\n",
      "    OPEN = {'BMP': (<class 'PIL.BmpImagePlugin.BmpImageFile'>, <function _...\n",
      "    ORDERED = 1\n",
      "    PERSPECTIVE = 2\n",
      "    PILLOW_VERSION = '4.1.1'\n",
      "    QUAD = 3\n",
      "    RASTERIZE = 2\n",
      "    RLE = 3\n",
      "    ROTATE_180 = 3\n",
      "    ROTATE_270 = 4\n",
      "    ROTATE_90 = 2\n",
      "    SAVE = {'BMP': <function _save>, 'GIF': <function _save>, 'JPEG': <fun...\n",
      "    SAVE_ALL = {'GIF': <function _save_all>, 'TIFF': <function _save_all>}\n",
      "    SEQUENCE = 1\n",
      "    TRANSPOSE = 5\n",
      "    USE_CFFI_ACCESS = False\n",
      "    VERSION = '1.1.7'\n",
      "    WEB = 0\n",
      "    logger = <logging.Logger object>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sized = testimage.resize((600,400), Image.NEAREST)\n",
    "sized.save(\"image_sized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "cropim = sized.crop((130,100,450,330))\n",
    "cropim.save(\"cropim.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "cvimg = cv2.imread('image_sized.png',0)\n",
    "ret,thresh1 = cv2.threshold(cvimg,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imwrite(\"thresh1.png\", thresh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!showme thresh1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img0 = Image.open(\"thresh1.png\")\n",
    "imga = img0.convert(\"RGBA\")\n",
    "imga\n",
    "imga.save(\"img0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"cropim.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(gray,(15,15),0)\n",
    "\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "cv2.imshow(\"Circled\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"image_sized.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 5, 5, 100, 100)\n",
    "ret,thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(thresh1, 100,200)\n",
    "imagem = cv2.bitwise_not(edges)\n",
    "\n",
    "res = cv2.bitwise_and(image,image, mask=imagem)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "#cv2.imshow(\"Circled\", image)\n",
    "#cv2.imshow(\"Thresh\", thresh1)\n",
    "#cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"imagem\", imagem)\n",
    "cv2.imshow(\"res\", res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "image = cv2.imread(\"image_sized.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 5, 5, 100, 100)\n",
    "ret,thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(image, 100,200)\n",
    "imagem = cv2.bitwise_not(edges)\n",
    "\n",
    "#res = cv2.bitwise_and(image,image, mask=imagem)\n",
    "res = cv2.bitwise_and(image,image, mask=thresh1)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "#cv2.imshow(\"Circled\", image)\n",
    "#cv2.imshow(\"Thresh\", thresh1)\n",
    "cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"imagem\", imagem)\n",
    "cv2.imshow(\"res\", res)\n",
    "\n",
    "cv2.imwrite(\"edges-01.png\", edges)\n",
    "cv2.imwrite(\"imagem-01.png\", imagem)\n",
    "cv2.imwrite(\"res.png-01\", res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "img_noblur = cv2.imread('image_sized.png', 0)\n",
    "img = cv2.blur(img_noblur, (7,7))\n",
    " \n",
    "canny_edge = cv2.Canny(img, 0, 0)\n",
    " \n",
    "#cv2.imshow('image', img)\n",
    "#cv2.imshow('canny_edge', canny_edge)\n",
    " \n",
    "cv2.createTrackbar('min_value','canny_edge',0,500,nothing)\n",
    "cv2.createTrackbar('max_value','canny_edge',0,500,nothing)\n",
    " \n",
    "\n",
    "     \n",
    "min_value = cv2.getTrackbarPos('min_value', 'canny_edge')\n",
    "max_value = cv2.getTrackbarPos('max_value', 'canny_edge')\n",
    " \n",
    "canny_edge = cv2.Canny(img, min_value, max_value)\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('canny_edge', canny_edge)    \n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 64\n",
      "threshold 71\n",
      "threshold 81\n",
      "threshold 95\n",
      "threshold 106\n",
      "threshold 117\n",
      "threshold 125\n",
      "threshold 134\n",
      "threshold 143\n",
      "threshold 144\n",
      "threshold 148\n",
      "threshold 149\n",
      "threshold 151\n",
      "threshold 152\n",
      "threshold 154\n",
      "threshold 156\n",
      "threshold 159\n",
      "threshold 165\n",
      "threshold 170\n",
      "threshold 175\n",
      "threshold 181\n",
      "threshold 186\n",
      "threshold 189\n",
      "threshold 185\n",
      "threshold 182\n",
      "threshold 178\n",
      "threshold 177\n",
      "threshold 171\n",
      "threshold 170\n",
      "threshold 169\n",
      "threshold 165\n",
      "threshold 162\n",
      "threshold 147\n",
      "threshold 141\n",
      "threshold 136\n",
      "threshold 130\n",
      "threshold 128\n",
      "threshold 123\n",
      "threshold 122\n",
      "threshold 119\n",
      "threshold 114\n",
      "threshold 110\n",
      "threshold 106\n",
      "threshold 100\n",
      "threshold 93\n",
      "threshold 92\n",
      "threshold 89\n",
      "threshold 88\n",
      "threshold 86\n",
      "threshold 82\n",
      "threshold 80\n",
      "threshold 75\n",
      "threshold 71\n",
      "threshold 67\n",
      "threshold 62\n",
      "threshold 60\n",
      "threshold 59\n",
      "threshold 58\n",
      "threshold 55\n",
      "threshold 53\n",
      "threshold 51\n",
      "threshold 47\n",
      "threshold 41\n",
      "threshold 37\n",
      "threshold 32\n",
      "threshold 27\n",
      "threshold 23\n",
      "threshold 18\n",
      "threshold 16\n",
      "threshold 14\n",
      "threshold 12\n",
      "threshold 8\n",
      "threshold 7\n",
      "threshold 3\n",
      "threshold 0\n",
      "threshold 5\n",
      "threshold 11\n",
      "threshold 14\n",
      "threshold 18\n",
      "threshold 21\n",
      "threshold 27\n",
      "threshold 29\n",
      "threshold 32\n",
      "threshold 33\n",
      "threshold 34\n",
      "threshold 36\n",
      "threshold 40\n",
      "threshold 43\n",
      "threshold 47\n",
      "threshold 48\n",
      "threshold 52\n",
      "threshold 55\n",
      "threshold 56\n",
      "threshold 59\n",
      "gaussian blur kernel size 2\n",
      "gaussian blur kernel size 1\n",
      "gaussian blur kernel size 0\n",
      "gaussian blur kernel size 1\n",
      "gaussian blur kernel size 2\n",
      "gaussian blur kernel size 3\n",
      "gaussian blur kernel size 4\n",
      "gaussian blur kernel size 5\n",
      "gaussian blur kernel size 6\n",
      "gaussian blur kernel size 7\n",
      "gaussian blur kernel size 8\n",
      "gaussian blur kernel size 9\n",
      "gaussian blur kernel size 8\n",
      "gaussian blur kernel size 7\n",
      "gaussian blur kernel size 6\n",
      "threshold 60\n",
      "threshold 62\n",
      "threshold 63\n",
      "threshold 64\n",
      "threshold 67\n",
      "threshold 70\n",
      "threshold 73\n",
      "threshold 77\n",
      "threshold 80\n",
      "threshold 84\n",
      "threshold 86\n",
      "threshold 90\n",
      "threshold 93\n",
      "threshold 99\n",
      "threshold 100\n",
      "threshold 101\n",
      "threshold 103\n",
      "threshold 104\n",
      "threshold 106\n",
      "threshold 107\n",
      "threshold 110\n",
      "threshold 111\n",
      "threshold 114\n",
      "threshold 118\n",
      "threshold 121\n",
      "threshold 123\n",
      "threshold 126\n",
      "threshold 132\n",
      "threshold 133\n",
      "threshold 137\n",
      "threshold 138\n",
      "threshold 137\n",
      "threshold 136\n",
      "threshold 133\n",
      "threshold 129\n",
      "threshold 126\n",
      "threshold 123\n",
      "threshold 122\n",
      "threshold 118\n",
      "threshold 117\n",
      "threshold 112\n",
      "threshold 108\n",
      "threshold 104\n",
      "threshold 101\n",
      "threshold 95\n",
      "threshold 90\n",
      "threshold 82\n",
      "threshold 81\n",
      "threshold 78\n",
      "threshold 77\n",
      "threshold 74\n",
      "threshold 71\n",
      "threshold 70\n",
      "threshold 69\n",
      "threshold 67\n",
      "threshold 64\n",
      "threshold 63\n",
      "threshold 62\n",
      "threshold 58\n",
      "threshold 56\n",
      "threshold 55\n",
      "threshold 53\n",
      "threshold 51\n",
      "threshold 49\n",
      "threshold 44\n",
      "threshold 45\n",
      "threshold 47\n",
      "threshold 49\n",
      "threshold 52\n",
      "threshold 58\n",
      "threshold 63\n",
      "threshold 69\n",
      "threshold 73\n",
      "threshold 78\n",
      "threshold 82\n",
      "threshold 84\n",
      "threshold 89\n",
      "threshold 92\n",
      "threshold 96\n",
      "threshold 97\n",
      "threshold 99\n",
      "threshold 103\n",
      "threshold 104\n",
      "threshold 106\n",
      "threshold 110\n",
      "threshold 111\n",
      "threshold 118\n",
      "threshold 119\n",
      "threshold 121\n",
      "threshold 123\n",
      "threshold 125\n",
      "threshold 126\n",
      "threshold 128\n",
      "threshold 130\n",
      "threshold 132\n",
      "threshold 133\n",
      "threshold 134\n",
      "threshold 130\n",
      "threshold 125\n",
      "threshold 121\n",
      "threshold 115\n",
      "threshold 110\n",
      "threshold 104\n",
      "threshold 99\n",
      "threshold 96\n",
      "threshold 95\n",
      "threshold 92\n",
      "threshold 89\n",
      "threshold 88\n",
      "threshold 85\n",
      "threshold 84\n",
      "threshold 82\n",
      "threshold 81\n",
      "threshold 78\n",
      "threshold 77\n",
      "threshold 75\n",
      "threshold 74\n",
      "threshold 69\n",
      "threshold 67\n",
      "threshold 62\n",
      "threshold 60\n",
      "threshold 58\n",
      "threshold 51\n",
      "threshold 48\n",
      "threshold 44\n",
      "threshold 43\n",
      "threshold 40\n",
      "threshold 37\n",
      "threshold 34\n",
      "threshold 33\n",
      "threshold 27\n",
      "threshold 26\n",
      "threshold 23\n",
      "threshold 19\n",
      "threshold 16\n",
      "threshold 18\n",
      "threshold 21\n",
      "threshold 22\n",
      "threshold 27\n",
      "threshold 30\n",
      "threshold 32\n",
      "threshold 34\n",
      "gaussian blur kernel size 5\n",
      "gaussian blur kernel size 4\n",
      "gaussian blur kernel size 3\n",
      "gaussian blur kernel size 2\n",
      "gaussian blur kernel size 1\n",
      "gaussian blur kernel size 0\n",
      "threshold 45\n",
      "threshold 49\n",
      "threshold 53\n",
      "threshold 56\n",
      "threshold 58\n",
      "threshold 60\n",
      "threshold 62\n",
      "threshold 64\n",
      "threshold 67\n",
      "threshold 70\n",
      "threshold 71\n",
      "threshold 75\n",
      "threshold 77\n",
      "threshold 78\n",
      "threshold 84\n",
      "threshold 88\n",
      "threshold 90\n",
      "threshold 93\n",
      "threshold 96\n",
      "threshold 99\n",
      "threshold 101\n",
      "threshold 103\n",
      "threshold 104\n",
      "threshold 103\n",
      "threshold 101\n",
      "threshold 100\n",
      "threshold 97\n",
      "threshold 96\n",
      "threshold 95\n",
      "threshold 90\n",
      "threshold 89\n",
      "threshold 86\n",
      "threshold 84\n",
      "threshold 81\n",
      "threshold 80\n",
      "threshold 77\n",
      "threshold 74\n",
      "threshold 73\n",
      "threshold 70\n",
      "threshold 69\n",
      "threshold 67\n",
      "threshold 66\n",
      "threshold 63\n",
      "threshold 64\n",
      "threshold 67\n",
      "threshold 69\n",
      "threshold 70\n",
      "threshold 71\n",
      "threshold 74\n",
      "threshold 73\n",
      "threshold 71\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/imgproc/src/smooth.cpp:2098: error: (-215) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function createGaussianKernels\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e1b67f1120d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Gaussian Blur ( x2 +1 = odd number for kernel size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mkernelSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gaussian blur'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/imgproc/src/smooth.cpp:2098: error: (-215) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function createGaussianKernels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# slider callbacks\n",
    "def printThreshold(x):\n",
    "    print \"threshold\",x\n",
    "def printGaussianBlur(x):\n",
    "    print \"gaussian blur kernel size\",x\n",
    "# make a window to add sliders/preview to\n",
    "cv2.namedWindow('processed')\n",
    "#make some sliders\n",
    "cv2.createTrackbar('threshold','processed',60,255,printThreshold)\n",
    "cv2.createTrackbar('gaussian blur','processed',3,10,printGaussianBlur)\n",
    "# load image\n",
    "img = cv2.imread('image_sized.png')\n",
    "# continously process for quick feedback\n",
    "while 1:\n",
    "    # exit on ESC key\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Gaussian Blur ( x2 +1 = odd number for kernel size)\n",
    "    kernelSize = ((cv2.getTrackbarPos('gaussian blur','processed') * 2) + 1)\n",
    "    blur = cv2.GaussianBlur(img,(kernelSize,kernelSize),0)\n",
    "    # Threshold\n",
    "    ret,thresh = cv2.threshold(blur,cv2.getTrackbarPos('threshold','processed',),255,0)\n",
    "    # show result\n",
    "    cv2.imshow('processed ',thresh)\n",
    "\n",
    "# exit\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black and White  img = cv2.imread('image_sized.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 63\n",
      "threshold 64\n",
      "threshold 70\n",
      "threshold 74\n",
      "threshold 80\n",
      "threshold 81\n",
      "threshold 86\n",
      "threshold 88\n",
      "threshold 92\n",
      "threshold 93\n",
      "threshold 95\n",
      "threshold 99\n",
      "threshold 100\n",
      "threshold 101\n",
      "threshold 106\n",
      "threshold 107\n",
      "threshold 108\n",
      "threshold 111\n",
      "threshold 114\n",
      "threshold 115\n",
      "threshold 118\n",
      "threshold 121\n",
      "threshold 126\n",
      "threshold 129\n",
      "threshold 128\n",
      "threshold 123\n",
      "threshold 118\n",
      "threshold 110\n",
      "threshold 104\n",
      "threshold 100\n",
      "threshold 96\n",
      "threshold 93\n",
      "threshold 90\n",
      "threshold 86\n",
      "threshold 82\n",
      "threshold 80\n",
      "threshold 78\n",
      "threshold 75\n",
      "threshold 74\n",
      "threshold 71\n",
      "threshold 70\n",
      "threshold 69\n",
      "threshold 63\n",
      "threshold 62\n",
      "threshold 59\n",
      "threshold 56\n",
      "threshold 53\n",
      "threshold 52\n",
      "threshold 49\n",
      "threshold 48\n",
      "threshold 51\n",
      "threshold 53\n",
      "threshold 56\n",
      "threshold 58\n",
      "threshold 59\n",
      "threshold 60\n",
      "threshold 63\n",
      "threshold 66\n",
      "threshold 67\n",
      "threshold 71\n",
      "threshold 77\n",
      "threshold 78\n",
      "gaussian blur kernel size 2\n",
      "gaussian blur kernel size 1\n",
      "gaussian blur kernel size 0\n",
      "gaussian blur kernel size 1\n",
      "gaussian blur kernel size 2\n",
      "gaussian blur kernel size 3\n",
      "gaussian blur kernel size 4\n",
      "gaussian blur kernel size 5\n",
      "gaussian blur kernel size 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# slider callbacks\n",
    "def printThreshold(x):\n",
    "    print \"threshold\",x\n",
    "def printGaussianBlur(x):\n",
    "    print \"gaussian blur kernel size\",x\n",
    "# make a window to add sliders/preview to\n",
    "cv2.namedWindow('processed')\n",
    "#make some sliders\n",
    "cv2.createTrackbar('threshold','processed',60,255,printThreshold)\n",
    "cv2.createTrackbar('gaussian blur','processed',3,10,printGaussianBlur)\n",
    "# load image\n",
    "img = cv2.imread('image_sized.png',0)\n",
    "# continously process for quick feedback\n",
    "while 1:\n",
    "    # exit on ESC key\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Gaussian Blur ( x2 +1 = odd number for kernel size)\n",
    "    kernelSize = ((cv2.getTrackbarPos('gaussian blur','processed') * 2) + 1)\n",
    "    blur = cv2.GaussianBlur(img,(kernelSize,kernelSize),0)\n",
    "    # Threshold\n",
    "    ret,thresh = cv2.threshold(blur,cv2.getTrackbarPos('threshold','processed',),255,0)\n",
    "    # show result\n",
    "    cv2.imshow('processed ',thresh)\n",
    "\n",
    "# exit\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "#img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.namedWindow('hsv')\n",
    "cv2.namedWindow('masq')\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "img = cv2.imread('image_sized.png', 1)\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('R-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('G-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('G-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('B-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('B-high','image',0,255,nothing)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    #ret, img = cap.read()\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    rl = cv2.getTrackbarPos('R-low','image')\n",
    "    rh = cv2.getTrackbarPos('R-high','image')\n",
    "\n",
    "    gl = cv2.getTrackbarPos('G-low','image')\n",
    "    gh = cv2.getTrackbarPos('G-high','image')\n",
    "\n",
    "    bl = cv2.getTrackbarPos('B-low','image')\n",
    "    bh = cv2.getTrackbarPos('B-high','image')\n",
    "\n",
    "    lower = np.array([rl,gl,bl])\n",
    "    upper = np.array([rh,gh,bh])\n",
    "\n",
    "    #print(rl)\n",
    "\n",
    "    img[:] = [bl,gl,rl]\n",
    "\n",
    "    # Threshold the HSV image to get only certain colors\n",
    "    mask = cv2.inRange(hsv, lower, upper)    \n",
    "\n",
    "\n",
    "    res = cv2.bitwise_and(img, img, mask= mask)\n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('hsv',hsv)\n",
    "    cv2.imshow('res',res)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep above here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Program to blur image\n",
    "import cv2 \n",
    "#This will give an error if you don't have cv2 module\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "img = cv2.imread('image_sized.png', 1) \n",
    "\n",
    "cv2.createTrackbar('low','image',5,25,nothing)\n",
    "cv2.createTrackbar('high','image',5,25,nothing)\n",
    "\n",
    "while(1):\n",
    "  \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    \n",
    "    # get current positions of four trackbars\n",
    "    k1 = cv2.getTrackbarPos('low','image')\n",
    "    k2 = cv2.getTrackbarPos('high','image')\n",
    "    \n",
    "    lower = np.array([k1])\n",
    "    upper = np.array([k2])\n",
    "    \n",
    "    #make sure that you have saved it in the same folder\n",
    "    #blurImg = cv2.blur(img,(k1, k2)) #You can change the kernel size as you want\n",
    "    #cv2.imshow('blurred image',blurImg)\n",
    "    cv2.imshow('image',img)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    k1 = cv2.getTrackbarPos('low','image')\n",
    "    k2 = cv2.getTrackbarPos('high','image')\n",
    "\n",
    "    #print(rl)\n",
    "\n",
    "   \n",
    "\n",
    "    # Threshold the HSV image to get only certain colors\n",
    "    mask = cv2.inRange(hsv, lower, upper)    \n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ run above ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "#img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.namedWindow('hsv')\n",
    "cv2.namedWindow('masq')\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "img = cv2.imread('image_sized.png', 1)\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('R-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('G-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('G-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('B-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('B-high','image',0,255,nothing)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    #ret, img = cap.read()\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    rl = cv2.getTrackbarPos('R-low','image')\n",
    "    rh = cv2.getTrackbarPos('R-high','image')\n",
    "\n",
    "    gl = cv2.getTrackbarPos('G-low','image')\n",
    "    gh = cv2.getTrackbarPos('G-high','image')\n",
    "\n",
    "    bl = cv2.getTrackbarPos('B-low','image')\n",
    "    bh = cv2.getTrackbarPos('B-high','image')\n",
    "\n",
    "    lower = np.array([rl,gl,bl])\n",
    "    upper = np.array([rh,gh,bh])\n",
    "\n",
    "    #print(rl)\n",
    "\n",
    "    img[:] = [bl,gl,rl]\n",
    "\n",
    "    # Threshold the HSV image to get only certain colors\n",
    "    mask = cv2.inRange(hsv, lower, upper)    \n",
    "\n",
    "\n",
    "    res = cv2.bitwise_and(img, img, mask= mask)\n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('hsv',hsv)\n",
    "    cv2.imshow('res',res)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-c03d0c0a2c8c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-c03d0c0a2c8c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    low_val  = [  0   0   0 ..., 249 249 250],[math.floor(n_cols * half_percent)]\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "low_val  = [  0   0   0 ..., 249 249 250],[math.floor(n_cols * half_percent)]\n",
    "print low_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def nothing(x):\n",
    "    pass\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        # get current positions of four trackbars\n",
    "        r = cv2.getTrackbarPos('R','image')\n",
    "        g = cv2.getTrackbarPos('G','image')\n",
    "        b = cv2.getTrackbarPos('B','image')\n",
    "        s = cv2.getTrackbarPos(switch,'image')\n",
    "        if s == 0:\n",
    "            img[:] = 0\n",
    "        else:\n",
    "            img[:] = [b,g,r]\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Colors from a Trackbar\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "#img = np.zeros((300,512,3), np.uint8)\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "img = cv2.imread(\"image_sized.png\")\n",
    "\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','img')\n",
    "    g = cv2.getTrackbarPos('G','img')\n",
    "    b = cv2.getTrackbarPos('B','img')\n",
    "    s = cv2.getTrackbarPos(switch,'img')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "img_noblur = cv2.imread('image_sized.png', 0)\n",
    "img = cv2.blur(img_noblur, (7,7))\n",
    " \n",
    "canny_edge = cv2.Canny(img, 0, 0)\n",
    " \n",
    "cv2.createTrackbar('min_value','canny_edge',0,500,nothing)\n",
    "cv2.createTrackbar('max_value','canny_edge',0,500,nothing)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "min_value = cv2.getTrackbarPos('min_value', 'canny_edge')\n",
    "max_value = cv2.getTrackbarPos('max_value', 'canny_edge')\n",
    "\n",
    "canny_edge = cv2.Canny(img, min_value, max_value)\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('canny_edge', canny_edge)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "# exit on ESC key\n",
    "k = cv2.waitKey(1)\n",
    "if k == 27:\n",
    "\n",
    "        \n",
    "      \n",
    "        \n",
    "cv2.destroyAllWindows()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../face_morpher/image2.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../face_morpher/image2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d1e96535548f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HSV_Thresh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsv_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Video'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m37\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"../face_morpher/image2.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "#cv2.namedWindow('Video')\n",
    "#cv2.moveWindow('Video',5,5)\n",
    "#cv2.namedWindow('HSV_Thresh')\n",
    "#cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'cap')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"../face_morpher/image2.jpg\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "        for i in range(rows): #note the presence of colon\n",
    "            for j in range(cols):\n",
    "                if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "                    bavg=bavg+tone[i,j,0]\n",
    "                    gavg=gavg+tone[i,j,1]\n",
    "                    ravg=ravg+tone[i,j,2]\n",
    "                    numpix=numpix+1\n",
    "                    bavg=bavg/numpix\n",
    "                    gavg=gavg/numpix\n",
    "                    ravg=ravg/numpix\n",
    "                    '''print \"bavg=\"+str(bavg)\n",
    "                    print \"gavg=\"+str(gavg)\n",
    "                    print \"ravg=\"+str(ravg)\n",
    "                    print \"numpix=\"+str(numpix)'''\n",
    "                    cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "                    cv2.imshow('skin_mask', tone)\n",
    "                    hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "                    thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "                    thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "                    thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "                    cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "                    cv2.imshow('Video', img)\n",
    "                    k = cv2.waitKey(37)\n",
    "                    if k == 27:\n",
    "                        break\n",
    "                        cv2.destroyAllWindows()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6633c1fa86fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mthresh_hsv_toler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbavg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"../face_morpher/image2.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "cv2.namedWindow('Video')\n",
    "cv2.moveWindow('Video',5,5)\n",
    "cv2.namedWindow('HSV_Thresh')\n",
    "cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'Video')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "        for i in range(rows): #note the presence of colon\n",
    "            for j in range(cols):\n",
    "                if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "                    bavg=bavg+tone[i,j,0]\n",
    "                    gavg=gavg+tone[i,j,1]\n",
    "                    ravg=ravg+tone[i,j,2]\n",
    "                    numpix=numpix+1\n",
    "                    bavg=bavg/numpix\n",
    "                    gavg=gavg/numpix\n",
    "                    ravg=ravg/numpix\n",
    "                    '''print \"bavg=\"+str(bavg)\n",
    "                    print \"gavg=\"+str(gavg)\n",
    "                    print \"ravg=\"+str(ravg)\n",
    "                    print \"numpix=\"+str(numpix)'''\n",
    "                    cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "                    cv2.imshow('skin_mask', tone)\n",
    "                    hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "                    thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "                    thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "                    thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "                    cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "\n",
    "\n",
    "                    if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "                        break\n",
    "                    cv2.imshow('Video', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"image_sized.png\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "cv2.namedWindow('Video')\n",
    "cv2.moveWindow('Video',5,5)\n",
    "cv2.namedWindow('HSV_Thresh')\n",
    "cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'Video')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "        for i in range(rows): #note the presence of colon\n",
    "            for j in range(cols):\n",
    "                if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "                bavg=bavg+tone[i,j,0]\n",
    "                gavg=gavg+tone[i,j,1]\n",
    "                ravg=ravg+tone[i,j,2]\n",
    "                numpix=numpix+1\n",
    "                bavg=bavg/numpix\n",
    "                gavg=gavg/numpix\n",
    "                ravg=ravg/numpix\n",
    "                '''print \"bavg=\"+str(bavg)\n",
    "                print \"gavg=\"+str(gavg)\n",
    "                print \"ravg=\"+str(ravg)\n",
    "                print \"numpix=\"+str(numpix)'''\n",
    "                cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "                cv2.imshow('skin_mask', tone)\n",
    "                hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "                thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "                thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "                thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "                hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "                hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "\n",
    "\n",
    "                if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "                break\n",
    "                cv2.imshow('Video', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"image_sized.png\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "cv2.namedWindow('Video')\n",
    "cv2.moveWindow('Video',5,5)\n",
    "cv2.namedWindow('HSV_Thresh')\n",
    "cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'Video')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "    for i in range(rows): #note the presence of colon\n",
    "        for j in range(cols):\n",
    "            if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "            bavg=bavg+tone[i,j,0]\n",
    "            gavg=gavg+tone[i,j,1]\n",
    "            ravg=ravg+tone[i,j,2]\n",
    "            numpix=numpix+1\n",
    "            bavg=bavg/numpix\n",
    "            gavg=gavg/numpix\n",
    "            ravg=ravg/numpix\n",
    "            '''print \"bavg=\"+str(bavg)\n",
    "            print \"gavg=\"+str(gavg)\n",
    "            print \"ravg=\"+str(ravg)\n",
    "            print \"numpix=\"+str(numpix)'''\n",
    "            cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "            cv2.imshow('skin_mask', tone)\n",
    "            hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "            thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "            thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "            thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "            hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "            hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "\n",
    "\n",
    "        if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "break\n",
    "    cv2.imshow('Video', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting functions\n",
      "  Downloading functions-0.7.0.tar.gz\n",
      "Building wheels for collected packages: functions\n",
      "  Running setup.py bdist_wheel for functions ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jack/.cache/pip/wheels/42/a9/ca/ccff57e2a88fa39e8a76a4a3dced84e1486d857daf2a89d9e9\n",
      "Successfully built functions\n",
      "Installing collected packages: functions\n",
      "Successfully installed functions-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press SPACE to update the image\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/highgui/src/window.cpp:304: error: (-215) size.width>0 && size.height>0 in function imshow\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f2c1c0835b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Press SPACE to update the image\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/highgui/src/window.cpp:304: error: (-215) size.width>0 && size.height>0 in function imshow\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "Coherence-enhancing filtering example\n",
    "=====================================\n",
    "inspired by\n",
    "  Joachim Weickert \"Coherence-Enhancing Shock Filters\"\n",
    "  http://www.mia.uni-saarland.de/Publications/weickert-dagm03.pdf\n",
    "'''\n",
    "\n",
    "# Python 2/3 compatibility\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "PY3 = sys.version_info[0] == 3\n",
    "\n",
    "if PY3:\n",
    "    xrange = range\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def coherence_filter(img, sigma = 11, str_sigma = 11, blend = 0.5, iter_n = 4):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    for i in xrange(iter_n):\n",
    "        print(i)\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        eigen = cv2.cornerEigenValsAndVecs(gray, str_sigma, 3)\n",
    "        eigen = eigen.reshape(h, w, 3, 2)  # [[e1, e2], v1, v2]\n",
    "        x, y = eigen[:,:,1,0], eigen[:,:,1,1]\n",
    "\n",
    "        gxx = cv2.Sobel(gray, cv2.CV_32F, 2, 0, ksize=sigma)\n",
    "        gxy = cv2.Sobel(gray, cv2.CV_32F, 1, 1, ksize=sigma)\n",
    "        gyy = cv2.Sobel(gray, cv2.CV_32F, 0, 2, ksize=sigma)\n",
    "        gvv = x*x*gxx + 2*x*y*gxy + y*y*gyy\n",
    "        m = gvv < 0\n",
    "\n",
    "        ero = cv2.erode(img, None)\n",
    "        dil = cv2.dilate(img, None)\n",
    "        img1 = ero\n",
    "        img1[m] = dil[m]\n",
    "        img = np.uint8(img*(1.0 - blend) + img1*blend)\n",
    "    print('done')\n",
    "    return img\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    try:\n",
    "        fn = sys.argv[1]\n",
    "    except:\n",
    "        fn = 'image_sized.png'\n",
    "\n",
    "    src = cv2.imread(fn)\n",
    "\n",
    "    def nothing(*argv):\n",
    "        pass\n",
    "\n",
    "    def update():\n",
    "        sigma = cv2.getTrackbarPos('sigma', 'control')*2+1\n",
    "        str_sigma = cv2.getTrackbarPos('str_sigma', 'control')*2+1\n",
    "        blend = cv2.getTrackbarPos('blend', 'control') / 10.0\n",
    "        print('sigma: %d  str_sigma: %d  blend_coef: %f' % (sigma, str_sigma, blend))\n",
    "        dst = coherence_filter(src, sigma=sigma, str_sigma = str_sigma, blend = blend)\n",
    "        cv2.imshow('dst', dst)\n",
    "\n",
    "    cv2.namedWindow('control', 0)\n",
    "    cv2.createTrackbar('sigma', 'control', 9, 15, nothing)\n",
    "    cv2.createTrackbar('blend', 'control', 7, 10, nothing)\n",
    "    cv2.createTrackbar('str_sigma', 'control', 9, 15, nothing)\n",
    "\n",
    "\n",
    "    print('Press SPACE to update the image\\n')\n",
    "\n",
    "    cv2.imshow('src', src)\n",
    "    update()\n",
    "    while True:\n",
    "        ch = cv2.waitKey()\n",
    "        if ch == ord(' '):\n",
    "            update()\n",
    "        if ch == 27:\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "done\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d8a504af67ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#cv2.imwrite(\"coherence_filter.png\", coherence_filter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcoherence_filter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coherence_filter.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image_sized.png')\n",
    "\n",
    "coherence_filter(img, sigma = 11, str_sigma = 11, blend = 0.5, iter_n = 4)\n",
    "\n",
    "#cv2.imwrite(\"coherence_filter.png\", coherence_filter)\n",
    "coherence_filter.save(\"coherence_filter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma: 19  str_sigma: 19  blend_coef: 0.700000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-89726d434d25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-f2c1c0835b97>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mblend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'blend'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'control'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sigma: %d  str_sigma: %d  blend_coef: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoherence_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-f2c1c0835b97>\u001b[0m in \u001b[0;36mcoherence_filter\u001b[0;34m(img, sigma, str_sigma, blend, iter_n)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcoherence_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Colors from a Trackbar\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
